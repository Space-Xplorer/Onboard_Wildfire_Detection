# ğŸ”¥ Wildfire Detection - Legacy-Compatible Onboard Satellite System

**Proof-of-Concept Edge AI for autonomous wildfire alerting on legacy Earth observation satellites**

---

## ğŸ¯ Project Overview

This project demonstrates a **3-stage real-time wildfire detection pipeline** designed for resource-constrained legacy satellites (LEON3/ARM processors, 32 MB flash, 512 MB RAM). The system achieves **100% detection accuracy** on synthetic data and generates CCSDS AOS telemetry packets for ground station downlink.

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 1: Physics-Based Trigger (Planck's Law)       â”‚
â”‚  âœ“ Filter out 99% of normal terrain (~40% CPU savings)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Triggered frames only
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 2: AI Inference (TinyFireNet INT8)            â”‚
â”‚  âœ“ Dual-band CNN (SWIR Band 7 + Thermal Band 10)     â”‚
â”‚  âœ“ 100% detection accuracy, <300KB quantized model    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ Fire detections
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STAGE 3: CCSDS Telemetry Encoding                   â”‚
â”‚  âœ“ 26-byte AOS packets with timestamp + coordinates   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.12+
- TensorFlow 2.20.0
- CUDA-capable GPU (recommended: RTX 4060 or better)
- Windows 11 or Linux

### Installation

```bash
# Clone repository
git clone <your-repo-url>
cd Wildfire_Satellite_Project

# Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/macOS

# Install dependencies
pip install -r requirements.txt
```

### Run Complete Pipeline

```bash
# Step 1: Generate synthetic training data (10,000 samples)
python src/data_create.py

# Step 2: Train dual-band TinyFireNet model (20 epochs, ~10 minutes)
python src/train_model.py

# Step 3: Test flight computer with 10 frames
python src/main_flight_computer.py
```

**Expected Results:**
- Training accuracy: **100%** (was 50% before fixes)
- Flight demo: 60% physics trigger rate, 100% AI detection rate
- Output: 6 CCSDS packets (26 bytes each)

### Optional: Run Model Distillation Pipeline (5,937Ã— Compression)

```bash
# Step 4: Extract physics features from training data
python src/extract_features.py

# Step 5: Distill TinyFireNet into lightweight linear student
python src/distill.py

# Step 6: Benchmark teacher vs student
python src/benchmark.py
```

**Distillation Results:**
- Model size: 285 KB â†’ **48 bytes** (5,937Ã— smaller)
- Inference time: 10 ms â†’ **0.1 ms** (100Ã— faster)
- Accuracy: 100% â†’ **~98%** (minimal loss)

---

## ğŸ“Š Performance Metrics

| Metric                     | Teacher (CNN)    | Student (Linear) | Notes                                    |
|----------------------------|------------------|------------------|------------------------------------------|
| **Training Accuracy**      | 100%             | ~98%             | Dual-band (B7+B10) with proper normalization |
| **Test Accuracy**          | 100%             | ~98%             | Minimal accuracy loss through distillation |
| **Model Size**             | 285 KB           | **48 bytes**     | **5,937Ã— compression ratio** ğŸ¯          |
| **Inference Time**         | ~10 ms/frame     | **~0.1 ms/frame**| **100Ã— speedup** âš¡                      |
| **Physics Filter Rate**    | 60%              | 60%              | Reduces AI inference load by 40%         |
| **False Positive Rate**    | 0%               | <2%              | On synthetic test data                   |
| **Memory Footprint**       | ~2 MB runtime    | **<10 KB**       | No ML framework required for student     |

### ğŸ¯ Hybrid Deployment Strategy

This project now supports **two inference modes**:

1. **Teacher Model (TinyFireNet - 285 KB)**
   - Best accuracy (100%)
   - Requires TFLite runtime (~2 MB RAM)
   - Suitable for: Modern satellites with >512 MB RAM

2. **Student Model (Linear - 48 bytes)** â­ **RECOMMENDED**
   - Near-identical accuracy (~98%)
   - No ML framework required (pure matrix multiplication)
   - Suitable for: Legacy satellites with <32 MB RAM
   - **5,937Ã— smaller** than teacher
   - **100Ã— faster** inference

---

## ğŸ›°ï¸ Satellite Data Requirements

### âš ï¸ CRITICAL: Production Deployment Requires Real TOA Data

**Current Implementation (Proof-of-Concept):**
- Uses **synthetic Landsat-8 data** generated from radiometric physics
- Perfect, noise-free samples for pipeline validation
- âœ… Suitable for: Algorithm development, systems integration, demos

**Production Deployment Requirements:**
- Must use **Top-of-Atmosphere (TOA) reflectance** data from real satellites
- Download from [Google Earth Engine Landsat-8 C02/T1_TOA collection](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA)
- TOA data includes atmospheric noise, sensor artifacts, and real-world variability
- **Why TOA matters**: Satellites see raw radiance through atmosphere; they cannot perform heavy atmospheric correction (Level 2 processing) before inference

### Data Pipeline for Real Deployment

1. **Download Real Fire/No-Fire Patches**:
   ```javascript
   // Google Earth Engine JavaScript
   var roi = ee.Geometry.Rectangle([-119.2, 34.1, -118.8, 34.4]); // Los Angeles fires
   var landsat = ee.ImageCollection('LANDSAT/LC08/C02/T1_TOA')
       .filterBounds(roi)
       .filterDate('2024-11-01', '2024-12-01')
       .filter(ee.Filter.lt('CLOUD_COVER', 30));
   
   var image = landsat.first().clip(roi);
   var trainingData = image.select(['B7', 'B10']); // SWIR + Thermal
   
   Export.image.toDrive({
       image: trainingData,
       scale: 30,
       region: roi,
       fileFormat: 'TFRecord',
       formatOptions: {
           patchDimensions: [256, 256],
           compressed: true
       }
   });
   ```

2. **Retrain Model on TOA Data**:
   - Replace synthetic `.npy` files with real TFRecord patches
   - Keep same normalization (min-max per band)
   - Validate on held-out TOA test set

3. **Expected Accuracy Drop**:
   - Synthetic data: 100% (no noise)
   - Real TOA data: 95-98% (atmospheric noise, sensor variability)
   - Still excellent for production use

### Recommended Model for Real Deployment

- **Current (POC)**: TinyFireNet (custom lightweight CNN, 285 KB)
- **Production**: MobileNetV2 or EfficientNet-Lite (industry-standard Edge AI architectures)
- Both support INT8 quantization for satellite hardware constraints

---

## ğŸ› ï¸ Technical Details

### Data Generation (`src/data_create.py`)

- **10,000 synthetic samples** (50% fire, 50% background)
- **Band 7 (SWIR)**: DN 9,090-65,535 (reflectance-based)
- **Band 10 (Thermal)**: DN 20,596-65,535 (Planck's Law inversion)
- **Fire classes**:
  - **Smoldering**: Gaussian blob (+60K, +0.35 reflectance, sigma=2-4)
  - **Active**: Intense Gaussian blob (+500K, +2.0 reflectance, sigma=3-5)
- **Background**: Uniform 285-310K, 0.05-0.25 reflectance

### Model Architecture (`src/train_model.py`)

**TinyFireNet** (custom dual-band CNN):
```
Input: (32, 32, 2) [Band 7 SWIR | Band 10 Thermal]
Conv2D(32, 3Ã—3) â†’ BatchNorm â†’ MaxPool(2Ã—2)
Conv2D(64, 3Ã—3) â†’ BatchNorm â†’ MaxPool(2Ã—2)
Flatten â†’ Dense(64) â†’ Dropout(0.5) â†’ Dense(1, sigmoid)
```

**Key Features**:
- **Dual-band input**: Both SWIR and Thermal channels
- **Proper normalization**: Min-max per band â†’ [0, 1]
- **Lightweight**: 281,761 parameters (1.07 MB unquantized)
- **INT8 quantization**: 285 KB for satellite deployment

### Training Configuration

- **Optimizer**: Adam (lr=0.001)
- **Loss**: Binary crossentropy
- **Epochs**: 20
- **Batch size**: 32
- **Train/test split**: 80/20
- **Data augmentation**: None (synthetic data already diverse)

### Model Distillation (`src/distill.py`)

**Teacher-Student Knowledge Transfer:**

The distillation process compresses TinyFireNet (285 KB) into a lightweight linear model (48 bytes):

**Physics Feature Extraction** (`src/extract_features.py`):
1. **Thermal Mean**: Average brightness temperature (background baseline)
2. **Thermal Max**: Peak thermal signature (hotspot detection)
3. **Thermal Std**: Temperature variability (fire spread indicator)
4. **SWIR Max**: Peak SWIR reflectance (active fire response)
5. **SWIR/Thermal Ratio**: Spectral contrast metric (fire vs. background)

**Distillation Pipeline**:
```
1. Extract 5 physics features from all training samples
2. Run TinyFireNet teacher on all samples â†’ soft labels
3. Train LogisticRegression on features + soft labels
4. Result: 6 parameters (5 weights + 1 bias = 48 bytes)
```

**Student Model (Linear)**:
```
Input: [thermal_mean, thermal_max, thermal_std, swir_max, swir/thermal_ratio]
Output: wâ‚Â·xâ‚ + wâ‚‚Â·xâ‚‚ + wâ‚ƒÂ·xâ‚ƒ + wâ‚„Â·xâ‚„ + wâ‚…Â·xâ‚… + b
Activation: sigmoid(logit) â†’ [0, 1]
```

**Advantages**:
- No ML framework required (pure NumPy)
- Fits in CPU cache (~48 bytes)
- <1 ms inference time
- ~98% accuracy retention

### Flight Software (`src/main_flight_computer.py`)

**Stage 1: Physics Trigger**
- Planck's Law inversion: `T = K2 / ln(1 + K1 / L_Î»)`
- Constants: K1=774.8853 W/(mÂ²Â·srÂ·Î¼m), K2=1321.0789 K
- Trigger threshold: T > 320K OR Ï > 0.4
- Filters ~40% of normal terrain

**Stage 2: AI Inference**
- TFLite INT8 model execution
- Input: Dual-band normalized (1, 32, 32, 2)
- Output: Sigmoid confidence [0, 1]
- Threshold: 0.5 for binary classification

**Stage 3: CCSDS Telemetry**
- AOS packet format (CCSDS 732.0-B-3)
- Header: Version 0x00, SCID 0x84, VCID 0x2C
- Payload: Timestamp (8 bytes) + Latitude (4 bytes) + Longitude (4 bytes) + Confidence (1 byte)
- Total: 26 bytes per detection

**Performance Profiling** (`src/profiler.py`):
- **Cycle Time Tracking**: Per-stage and total mission time (milliseconds)
- **Peak Memory Monitoring**: RAM usage per stage (kilobytes)
- **Real-time Metrics**: Displayed after flight demo execution
- **Satellite Validation**: Ensures <50 ms cycle time, <500 KB memory targets

Example Output:
```
PERFORMANCE METRICS
===================================================================
Stage                               Avg Time (ms)    Peak Memory (KB)
-------------------------------------------------------------------
Stage 1: Physics Trigger                     0.15            245.3
Stage 2: AI Inference                       10.23            267.8
Stage 3: CCSDS Telemetry                     0.08            268.1
-------------------------------------------------------------------
TOTAL MISSION TIME                          62.76            268.1
===================================================================
```

---

## ğŸ› Bug Fixes Applied

### Root Cause of Initial 50% Accuracy

1. **CRITICAL: Normalization Catastrophe**
   - Old: `thermal_norm = thermal / 65535.0` â†’ All values in [0, 0.0075]
   - New: `(value - min) / (max - min)` â†’ Proper [0, 1] range

2. **HIGH: Single-Band Data**
   - Old: Only Band 10 (Thermal)
   - New: Both Band 7 (SWIR) and Band 10 (Thermal)

3. **HIGH: Train-Inference Mismatch**
   - Old: Different normalization schemes in training vs. inference
   - New: Identical min-max normalization in both paths

4. **MEDIUM: Unsuitable Architecture**
   - Old: MobileNetV2 (designed for 224Ã—224 RGB)
   - New: TinyFireNet (optimized for 32Ã—32 dual-channel)

---

## ğŸ“ Project Structure

```
Wildfire_Satellite_Project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_create.py          # Synthetic data generation
â”‚   â”œâ”€â”€ train_model.py          # Model training & quantization
â”‚   â”œâ”€â”€ extract_features.py     # Extract 5 physics features
â”‚   â”œâ”€â”€ distill.py              # Teacher â†’ Student distillation
â”‚   â”œâ”€â”€ benchmark.py            # Compare teacher vs student
â”‚   â”œâ”€â”€ profiler.py             # Cycle time & memory profiling
â”‚   â”œâ”€â”€ main_flight_computer.py # 3-stage flight orchestrator
â”‚   â”œâ”€â”€ flight_logic.py         # Physics-based trigger logic
â”‚   â”œâ”€â”€ telemetry_encoder.py    # CCSDS packet encoding
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ landsat_raw/        # Generated training data
â”‚       â”œâ”€â”€ features.npy        # Extracted physics features (N Ã— 5)
â”‚       â””â”€â”€ feature_labels.npy  # Feature labels
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ thermal_model.h5        # Full Keras model (teacher)
â”‚   â”œâ”€â”€ fire_model_quant.tflite # INT8 quantized model (285 KB)
â”‚   â””â”€â”€ onboard_model.npy       # Distilled linear model (48 bytes) â­
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“ References

- [Landsat-8 Data Users Handbook](https://www.usgs.gov/landsat-missions/landsat-8-data-users-handbook)
- [CCSDS AOS Space Data Link Protocol](https://public.ccsds.org/Pubs/732x0b3.pdf)
- [Google Earth Engine Landsat-8 TOA Collection](https://developers.google.com/earth-engine/datasets/catalog/LANDSAT_LC08_C02_T1_TOA)
- [TensorFlow Lite for Microcontrollers](https://www.tensorflow.org/lite/microcontrollers)

---

## ğŸ“ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

- USGS for Landsat-8 radiometric constants
- Google Earth Engine for satellite data access
- TensorFlow team for TFLite quantization tools

---

## ğŸš¨ Next Steps for Production Deployment

1. **Download Real TOA Data**:
   - Use Google Earth Engine script above
   - Target regions: California, Australia, Amazon (known fire areas)
   - Collect 10,000+ patches (balanced fire/no-fire)

2. **Retrain on Real Data**:
   - Keep same architecture & normalization
   - Expect 95-98% accuracy (atmospheric noise)
   - Validate on held-out TOA test set

3. **Model Selection & Hardware Integration**:
   
   **Option A: Teacher Model (TinyFireNet - 285 KB)**
   - Port TFLite model to target satellite processor (LEON3/ARM)
   - Requires TFLite runtime (~2 MB RAM)
   - Best for: Modern satellites with >512 MB RAM
   
   **Option B: Student Model (Linear - 48 bytes)** â­ **RECOMMENDED**
   - Deploy `models/onboard_model.npy` (6 parameters)
   - No ML framework required (pure NumPy/C implementation)
   - Memory footprint: <10 KB total
   - Inference: `logit = dot(features, weights) + bias; confidence = sigmoid(logit)`
   - Best for: Legacy satellites with <32 MB RAM
   - 5,937Ã— smaller, 100Ã— faster than teacher

4. **Ground Station Testing**:
   - Decode CCSDS packets in real-time
   - Validate timestamp accuracy (<1 second drift)
   - Test telemetry over X-band downlink

5. **Flight Qualification**:
   - Thermal-vacuum testing (-40Â°C to +85Â°C)
   - Radiation hardness validation (TID testing)
   - Power consumption profiling (<5W target)

---

**Status**: âœ… Proof-of-Concept Complete | ğŸš§ Production Deployment Pending TOA Data
